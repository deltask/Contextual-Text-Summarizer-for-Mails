{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing packages and modules\n",
    "import operator\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import gensim.models as gm\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.text import TextCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download(\"RegexpTokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1= \"He said the attackers left behind leaflets urging staff at the Ishtar Sheraton to stop working at the hotel and demanding U.S. forces leave Iraq.\"\n",
    "s2 = \"He said the attackers left behind leaflets urging workers at the Ishtar Sheraton to stop working at the hotel.\"\n",
    "s = [s1,s2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(s1,s2):\n",
    "    s = [s1,s2]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    s1_tokens = tokenizer.tokenize(s1)\n",
    "    s2_tokens = tokenizer.tokenize(s2)\n",
    "    s1_tokens_pos = nltk.pos_tag(s1_tokens)\n",
    "    s2_tokens_pos = nltk.pos_tag(s2_tokens)\n",
    "    #print (s1_tokens)\n",
    "    #print (s2_tokens)\n",
    "    filtered_s1_tokens = [w for w in s1_tokens if not w in stop_words]\n",
    "    filtered_s2_tokens = [w for w in s2_tokens if not w in stop_words]\n",
    "    sentences = [filtered_s1_tokens,filtered_s2_tokens]\n",
    "    word_features = filtered_s1_tokens + filtered_s2_tokens\n",
    "    return s1_tokens,s2_tokens,filtered_s1_tokens,filtered_s2_tokens,s1_tokens_pos,s2_tokens_pos,word_features,sentences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w2vmodel(sentences):\n",
    "    model = gm.Word2Vec(sentences,min_count = 1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41989054867307574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:9: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:20: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
     ]
    }
   ],
   "source": [
    "s1_tokens,s2_tokens,filtered_s1_tokens,filtered_s2_tokens,s1_tokens_pos,s2_tokens_pos,word_features,sentences = preprocessing(s1,s2)\n",
    "model = w2vmodel(sentences)\n",
    "final_score = finalsimscore(filtered_s1_tokens,filtered_s2_tokens,s1_tokens_pos,s2_tokens_pos,word_features,model)\n",
    "print (final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ri(si,wf,w2v):    \n",
    "    r = []\n",
    "    s_sent = si\n",
    "    word_features = wf\n",
    "    model = w2v\n",
    "    for i in word_features:\n",
    "        j_list=[]\n",
    "        for j in s_sent:\n",
    "            j_list.append(model.similarity(i,j))\n",
    "            #print (j_list)\n",
    "        max_val = max(j_list)\n",
    "        #print (max_val)\n",
    "        pos = j_list.index(max_val)\n",
    "        r.append(model[i]*pos)\n",
    "    return (r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#r1 ri\n",
    "def wosim(s1_tokens,s2_tokens,wf,wv):\n",
    "    s1_sent = s1_tokens\n",
    "    s2_sent = s2_tokens\n",
    "    word_features = wf\n",
    "    model = wv\n",
    "    r1 = ri(s1_sent,word_features,model)\n",
    "    r2 =ri(s2_sent,word_features,model)\n",
    "    r1 = np.array(r1)\n",
    "    r2 = np.array(r2)\n",
    "    #list(set(r1) - set(r2))\n",
    "    np_diff =np.sum(np.sum(np.square(np.subtract(r1,r2)),axis=1),axis = 0)\n",
    "    np_sum = np.sum(np.sum(np.square(np.add(r1,r2)),axis=1),axis=0)\n",
    "    wo_sim = 1-(np_diff/np_sum)\n",
    "    return (wo_sim)\n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf(s,w):\n",
    "    if w in s[0] or s[1]:\n",
    "        indices = [z for z, x in enumerate(s) if x == w]\n",
    "        if w in s[0] and s[1]:\n",
    "            denom = 2\n",
    "        else:\n",
    "            denom = 1\n",
    "        idf_val = math.log(len(s)/denom,10)\n",
    "        \n",
    "        if (idf_val == 0):\n",
    "            return (0.5)\n",
    "        else:\n",
    "            return (idf_val)\n",
    "    else:\n",
    "        return (0)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def semsim(a_tokens,b_tokens,wv,a_tokens_pos,b_tokens_pos,s):\n",
    "    a_tokens_words, a_tokens_tags = zip(*a_tokens_pos)\n",
    "    b_tokens_words, b_tokens_tags = zip(*b_tokens_pos)\n",
    "    numerator_list = []\n",
    "    denominator_list = []\n",
    "    for i in a_tokens:\n",
    "        #print (\"i\")\n",
    "        #print (i)\n",
    "        i_tag = a_tokens_tags[a_tokens.index(i)]\n",
    "        if i_tag in b_tokens_tags:\n",
    "            indices = [z for z, x in enumerate(b_tokens_tags) if x == i_tag]\n",
    "            #print ('indices')\n",
    "            #print (indices)\n",
    "            sim_list = []\n",
    "            for k in indices:\n",
    "                #print (\"b\")\n",
    "                #print (b_tokens_words[k])\n",
    "                if i and b_tokens_words[k] in wv.wv.vocab:\n",
    "                    #print(\"sim\")\n",
    "                    sim_list.append(wv.similarity(i,b_tokens_words[k]))\n",
    "                    #print(sim_list)\n",
    "                \n",
    "                #print(sim_list)\n",
    "                          \n",
    "        else:\n",
    "            continue\n",
    "        #print (sim_list)\n",
    "        if not sim_list:\n",
    "            max_sim = 0\n",
    "        else:\n",
    "            max_sim = max(sim_list)\n",
    "            \n",
    "        numerator_list.append(float(max_sim) * float(idf(s,i)))\n",
    "        denominator_list.append(idf(s,i))\n",
    "    semsim_val = sum(numerator_list)/sum(denominator_list)\n",
    "    return semsim_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final similarity score\n",
    "def finalsimscore(s1_tokens,s2_tokens,filtered_s1_tokens,filtered_s2_tokens,s1_tokens_pos,s2_tokens_pos,word_features,model):\n",
    "    sentences = [s1_tokens,s2_tokens]\n",
    "    s = sentences\n",
    "    wo_sim = wosim(filtered_s1_tokens,filtered_s2_tokens,word_features,model)\n",
    "    sem_sim =semsim(filtered_s1_tokens,filtered_s2_tokens,model,s1_tokens_pos,s2_tokens_pos,s) + semsim(filtered_s2_tokens,filtered_s1_tokens,model,s2_tokens_pos,s1_tokens_pos,s)\n",
    "    alpha = 0.8\n",
    "    final_score = (alpha * sem_sim) + (1-alpha)*(wo_sim)\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Inputs():\n",
    "\n",
    "    m1 = \"Greetings from Indian Oil we read an article on a certain product of your company. We would like to know the inquire the details of that certain product which you have mentioned on Times Of India. Thank You for cooperating with us\"\n",
    "    m2 = \"Thank you for showing interest in the product. We would send you the details of the quotation shortly\"\n",
    "    m3 = \"I am attaching a quotation in response and in compliance with the tender mentioned earlier. Please do review this and let me know\"\n",
    "    m4 = \"Kindly send us your bank details so that we may make the payment. On receipt of the consignment we will confirm the details of the transaction. The finance is provided by our bankers on credit. The quality should be of the best in the market so that we can expand our business\"\n",
    "    I = [m1,m2,m3,m4]\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-207-2592f69a4eae>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-207-2592f69a4eae>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    def 1Inputs():\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "    #take 10 mails from m1 to m10\n",
    "def 1Inputs():\n",
    "    \n",
    "    m1 = \"A long time ago, there were four families who lived in a small village in Somalia. The first family would argue all of the time, the second family were very greedy, the third family were always away from the village exploring because they were never happy with what they had or where they lived. But the fourth family were calm and patient, and they enjoyed living in their small community\"\n",
    "    m2 = \"One night, the daughter of the third family was out exploring when she discovered a well hidden among some trees in the wilderness. The daughter ran back to her family and told them about the well and so they started to use the well to get their water\"\n",
    "    m3 = \"It was not long before the other families heard news of the well, and very soon all four families were using the well to get their water until it was in danger of running dry.This went on for some time, and it was obvious that the water in the well was getting lower and lower, yet none of the families wanted to stop using the well as it was close to the village and meant that they did not have to walk so far to get the water which they used to drink and cook and clean with.One day, the wise chief, who had always known about the secret well, spoke to each family in turn. The chief said to them, Tonight you must stay in your homes. You must not use the well for one whole night, that way the water will have time to rise once more\"\n",
    "    m4 = \"Each of the families agreed to stay away from the well, especially as the wise chief warned that there would be a severe punishment for any family who disobeyed this simple rule.But when night fell, the son of the first family could not resist visiting the well as he wanted to make sure he had plenty of water for the following day so that his family would not argue over who would walk the long distance to the usual well used by the rest of the villagers\"\n",
    "    m5 = \"He crept out to the well carrying two large buckets and filled them both to the top before returning to his home and hiding the buckets where they would not be seen.Not long after, the son of the second family also crept out to the well and filled two large buckets all the way to the top as he was very greedy and wanted the water for his family alone\"\n",
    "    m6 = \"Then the daughter of the third family also crept out to the well as she could not resist exploring at night and reasoned that it was she who had discovered the well in the first place so it was her family who deserved the extra water despite the warning from the wise chief\"\n",
    "    m7 = \"The next day, the chief visited the well and was distressed to find that it was completely dry. He waited until he knew that all of the families were away from their homes, then he visited each home in turn\"\n",
    "    m8 = \"In the first home he discovered the two buckets, one of which was already empty, but the other still contained the water which was stolen from the well. When he visited the second and third homes he also discovered the buckets of water hidden where nobody would see them. But when he visited the fourth home he discovered that the buckets were dry and realised that the patient family had remained in their beds all night. They had listened to his warning and had stayed away from the well so that the water might rise once more\"\n",
    "    m9 = \"The wise chief called all four families to the meeting place in the village where he confronted them about the well. You three families all stole water from the well even though I told you not to, said the chief in a stern voice. I know this because I visited your homes this morning and discovered the buckets of water. Because you defied my instructions you will be forced to remain in your homes for thirty days and nights without food or water as punishment. I hope that you will spend this time thinking about the wrong you have done\"\n",
    "    m10 = \"To the fourth family he said, You listened to my simple instructions and stayed in your home last night and did not visit the well. Take this letter and open it when you return to your home\"\n",
    "    m11 = \"The fourth family took the letter and returned home. When they opened the letter there was a map inside. The family followed the directions on the map and after travelling for many miles they discovered a well surrounded by an abundance of fruit trees and vegetable plants. There was enough food and water to last the family a whole lifetime.The families who were forced to stay in their homes without food or water learned a valuable lesson that day. They learned that it was always best to listen to the advice of oneâ€™s elders and not to take things when you were told not to. They also realised that the fourth family were rewarded for their patience and their willingness to follow the simple rules which benefit a community\"\n",
    "    I = [m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11]\n",
    "    return I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-208-1024c8ad4ede>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-208-1024c8ad4ede>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    def 2Inputs():\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "    #take 10 mails from m1 to m10\n",
    "def 2Inputs():\n",
    "    m1 = \"The theme of this research is mobile transaction processing systems focusing on versatile data sharing mechanisms in volatile mobile environments\"\n",
    "    m2 = \"The rapid growth of wireless network technologies and portable computing devices has promoted a new mobile working environment\"\n",
    "    m3 = \"A mobile environment is different from the traditional distributed environment due to its unique characteristics the mobility of users or computers the frequent and unpredictable disconnections of wireless networks and the resource constraints of mobile computing devices\"\n",
    "    m4 = \"On the one hand the mobile environment promotes a new working model people can carry out their work while being on the move.The environment for accessing and processing information is changing rapidly from stationary and location dependent to mobile and location independent.On the other hand these unique characteristics of the mobile environment pose many challenges to mobile transaction processing systems especially in terms of long delaying periods data unavailability and data inconsistency\"\n",
    "    \n",
    "    I = [m1,m2,m3,m4]\n",
    "    \n",
    "    return I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iniitialweights():\n",
    "    I = Inputs()\n",
    "    W = []\n",
    "    for  i in I:\n",
    "        W.append(int(1))\n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hiddenlayer(iteration):\n",
    "    index_input = 0\n",
    "    index_end = 0\n",
    "    I = Inputs()\n",
    "    if (iteration == 1):\n",
    "        W = iniitialweights()\n",
    "    current_mail_val = I[-1]\n",
    "    current_mail = current_mail_val.split('.')\n",
    "    sentence_final_score = {}\n",
    "    for i in range(1,4):  #nodes loop 3\n",
    "        I = Inputs()\n",
    "        L = len(I)\n",
    "        if (L/3 == 0):\n",
    "            n = L/3\n",
    "            #print (n)\n",
    "        else:\n",
    "            if (i == 1):\n",
    "                n = math.floor((L/3) + 1)\n",
    "                index_input = 0\n",
    "            else:\n",
    "                n = math.floor(L/3)\n",
    "        input_node = []\n",
    "        for index in range(index_input,index_input+n):   #mails loop from I\n",
    "            input_node.append(I[index])\n",
    "        #print (current_mail)\n",
    "        dict_index = -1\n",
    "        for sentence_current in current_mail:       #sentence current\n",
    "            #print (sentence_current)\n",
    "            dict_index = dict_index + 1\n",
    "            mail_final_score = {}                   \n",
    "            for mail_val in input_node:               #mail from mails       \n",
    "                mail = mail_val.split('.')\n",
    "                sum_final_score = 0\n",
    "                for sentence_prev in mail:      #sentence from mail\n",
    "                    #print (sentence_prev)\n",
    "                    s1_tokens,s2_tokens,filtered_s1_tokens,filtered_s2_tokens,s1_tokens_pos,s2_tokens_pos,word_features,sentences = preprocessing(sentence_current,sentence_prev)\n",
    "                    model = w2vmodel(sentences)\n",
    "                    final_score = finalsimscore(s1_tokens,s2_tokens,filtered_s1_tokens,filtered_s2_tokens,s1_tokens_pos,s2_tokens_pos,word_features,model)\n",
    "                    sum_final_score = sum_final_score + final_score\n",
    "                key = I.index(mail_val)\n",
    "                mail_final_score[key] = sum_final_score\n",
    "            #print (i)\n",
    "            #print (sentence_final_score)\n",
    "            if (i== 1):\n",
    "                sentence_final_score[current_mail.index(sentence_current)] = mail_final_score\n",
    "                #print (\"i is 1\",current_mail_val.index(sentence_current))\n",
    "            else:\n",
    "                #print (current_mail_val.index(sentence_current))\n",
    "                #sentence_final_score[current_mail_val.index(sentence_current)].update(mail_final_score)\n",
    "                sentence_final_score[dict_index].update(mail_final_score)\n",
    "        index_input = index_input + n\n",
    "    #print (sentence_final_score)\n",
    "    return (sentence_final_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def final_ouptut(beta,iteration):\n",
    "    sentence_final_score = hiddenlayer(iteration)\n",
    "    L= len(Inputs()[-1].split(\".\"))\n",
    "    retrieval = math.floor(beta * L)\n",
    "    sum_score = ({k:sum(v.values()) for k,v in sentence_final_score.items()})\n",
    "    newA = dict(sorted(sum_score.items(), key=operator.itemgetter(1), reverse=True)[:retrieval])\n",
    "    newA_key = sorted(newA)\n",
    "    cm = Inputs()[-1].split('.')\n",
    "    #return {(cm[k])  for k in newA_key}\n",
    "    return (newA_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize():\n",
    "    \n",
    "    beta = 0.5\n",
    "    iteration = 1\n",
    "    print (\"Original Sentence: \")\n",
    "    print (Inputs()[-1])\n",
    "    cm = Inputs()[-1].split('.')\n",
    "    print (\" \")\n",
    "\n",
    "    print (\"current sentence : \")\n",
    "    newA_key = final_ouptut(beta,iteration)\n",
    "    #print (newA_key)\n",
    "    for j in newA_key:\n",
    "        print (cm[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: \n",
      "Kindly send us your bank details so that we may make the payment. On receipt of the consignment we will confirm the details of the transaction. The finance is provided by our bankers on credit. The quality should be of the best in the market so that we can expand our business\n",
      " \n",
      "current sentence : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:9: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:20: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kindly send us your bank details so that we may make the payment\n",
      " The quality should be of the best in the market so that we can expand our business\n"
     ]
    }
   ],
   "source": [
    "summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict1 = {'1.2': {1:2,2:3,3:5}, '2.2': {1:2,2:3}, '3.3': {1:2,2:3}}\n",
    "\n",
    "for k,v in dict1.items():\n",
    "    for key,val in v.items():\n",
    "        if key in newdict:\n",
    "            newdict\n",
    "        \n",
    "#print({key:sum(value_1.values()) for k,v in dict1.items() for key,value_1 in v.items()})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {1: 6, 2: 7, 3: 8, 4: 3, 5: 4, 6: 5}, 2: {1: 4, 2: 5, 3: 7}}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dict = {1:{1:6,2:7,3:8},2:{1:4,2:5,3:7}}\n",
    "sample_dict[1].update({4:3,5:4,6:5})\n",
    "sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4+1):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:9: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:20: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node\n",
      "2\n",
      "node\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {0: 1.2044923746847509,\n",
       "  1: 0.88917064523213396,\n",
       "  2: 1.4470215424432271,\n",
       "  3: 0.68228528333286964,\n",
       "  4: 0.53333814935290924,\n",
       "  5: 0.29266244818861498,\n",
       "  6: 0.65681182993322129,\n",
       "  7: 0.94830013728707785,\n",
       "  8: 1.4800270771538926,\n",
       "  9: 0.60366587018442952},\n",
       " 1: {0: 0.2282598972152014,\n",
       "  1: 0.32574491765737951,\n",
       "  2: 0.76945756833882095,\n",
       "  3: 0.23631498655356192,\n",
       "  4: 0.18855901095005784,\n",
       "  5: 0.15343871139978355,\n",
       "  6: 0.32716721410463256,\n",
       "  7: 0.84467253326930181,\n",
       "  8: 0.67357495405882695,\n",
       "  9: 0.35578288214543846},\n",
       " 2: {0: 0.98119845582171483,\n",
       "  1: 1.0280168447147535,\n",
       "  2: 1.3247769630700659,\n",
       "  3: 0.58092757347124158,\n",
       "  4: 0.5033467415828824,\n",
       "  5: 0.36687880975368492,\n",
       "  6: 0.54613574295022027,\n",
       "  7: 0.97263247531454022,\n",
       "  8: 1.3088753402226605,\n",
       "  9: 0.35408740142835554},\n",
       " 3: {0: 1.1649121197271231,\n",
       "  1: 0.89816903181489161,\n",
       "  2: 1.6342383068384532,\n",
       "  3: 0.81538093497453989,\n",
       "  4: 0.73980709090860275,\n",
       "  5: 0.40995542709770438,\n",
       "  6: 0.43418704335408248,\n",
       "  7: 1.4979726139450842,\n",
       "  8: 1.4685413538419669,\n",
       "  9: 0.55313574427610401},\n",
       " 4: {0: 0.79087241890189908,\n",
       "  1: 0.5750072298681006,\n",
       "  2: 1.6952908560147391,\n",
       "  3: 0.49496432357720349,\n",
       "  4: 0.33983153059704663,\n",
       "  5: 0.16657790304185727,\n",
       "  6: 0.79698611955973475,\n",
       "  7: 0.76882855103895364,\n",
       "  8: 1.3674154334247355,\n",
       "  9: 0.27392750076424177},\n",
       " 5: {0: 0.55437291052665483,\n",
       "  1: 0.31808603434649929,\n",
       "  2: 0.95670812742421407,\n",
       "  3: 0.28823950834569123,\n",
       "  4: 0.31333993631752755,\n",
       "  5: 0.12646773197905353,\n",
       "  6: 0.326726695849824,\n",
       "  7: 0.83069729914634927,\n",
       "  8: 1.0588434910257047,\n",
       "  9: 0.36664964264747035},\n",
       " 6: {0: 0.76061425183257825,\n",
       "  1: 0.40237731419084033,\n",
       "  2: 0.92396701901563794,\n",
       "  3: 0.50039507896489721,\n",
       "  4: 0.50353590813064442,\n",
       "  5: 0.26478604913718828,\n",
       "  6: 0.38498830726299194,\n",
       "  7: 1.0674280599446788,\n",
       "  8: 1.0555654024193397,\n",
       "  9: 0.38999200474693974}}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hiddenlayer_1(iteration):\n",
    "    for iter_value in range(1,iteration+1):\n",
    "        index_input = 0\n",
    "        index_end = 0\n",
    "        I = Inputs()\n",
    "        if (iter_value == 1):\n",
    "            W = iniitialweights()\n",
    "        current_mail_val = I[-1]\n",
    "        current_mail = current_mail_val.split('.')\n",
    "        sentence_final_score = {}\n",
    "        for i in range(1,4):  #nodes loop 3\n",
    "            I = Inputs()\n",
    "            L = len(I)\n",
    "            if (L/3 == 0):\n",
    "                n = L/3\n",
    "                print (n)\n",
    "            else:\n",
    "                if (i == 1):\n",
    "                    n = math.floor((L/3) + 1)\n",
    "                    index_input = 0\n",
    "                else:\n",
    "                    n = math.floor(L/3)\n",
    "            input_node = []\n",
    "            for index in range(index_input,index_input+n):   #mails loop from I\n",
    "                input_node.append(I[index])\n",
    "\n",
    "            for sentence_current in current_mail:       #sentence current\n",
    "                mail_final_score = {}                   \n",
    "                for mail_val in input_node:               #mail from mails       \n",
    "                    mail = mail_val.split('.')\n",
    "                    sum_final_score = 0\n",
    "                    for sentence_prev in mail:      #sentence from mail\n",
    "                        s1_tokens,s2_tokens,filtered_s1_tokens,filtered_s2_tokens,s1_tokens_pos,s2_tokens_pos,word_features,sentences = preprocessing(sentence_current,sentence_prev)\n",
    "                        model = w2vmodel(sentences)\n",
    "                        final_score = finalsimscore(filtered_s1_tokens,filtered_s2_tokens,s1_tokens_pos,s2_tokens_pos,word_features,model)\n",
    "                        sum_final_score = sum_final_score + final_score\n",
    "                    key = I.index(mail_val)\n",
    "                    mail_final_score[key] = sum_final_score\n",
    "                if (i== 1):\n",
    "                    sentence_final_score[current_mail.index(sentence_current)] = mail_final_score\n",
    "                else:\n",
    "                    sentence_final_score[current_mail.index(sentence_current)].update(mail_final_score)\n",
    "            index_input = index_input + n\n",
    "            W = W\n",
    "    return (sentence_final_score)\n",
    "        \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.009433962264150943, 0.08018867924528301, 0.049528301886792456, 0.02358490566037736, 0.014150943396226415, 0.10613207547169812, 1.0, 0.21226415094339623]\n"
     ]
    }
   ],
   "source": [
    "x = [0,4,34,21,10,6,45,424,90]\n",
    "array = []\n",
    "for element in x:\n",
    "    normalized = (element-min(x))/(max(x)-min(x))\n",
    "    array.append(normalized)\n",
    "print (array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = w2vmodel(preprocessed_output[sentences])\n",
    "                    final_score = final_score(preprocessed_output[filtered_s1_tokens],preprocessed_output[filtered_s2_tokens],preprocessed_output[s1_tokens_pos],preprocessed_output[s2_tokens_pos],preprocessed_output[word_features],model)\n",
    "                    sum_final_score = sum_final_score + final_score\n",
    "                mail_final_score[key] = sum_final_score\n",
    "                key = key + 1\n",
    "            sentence_final_score.append(mail_final_score)\n",
    "                       \n",
    "        index_input = index_input + n\n",
    "        return sentence_final_score\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for mail in input_node:\n",
    "            mail = mail.split('.')\n",
    "            for sentence_current in current_mail:\n",
    "                current_mail_sentence_sentence_prev= {}\n",
    "                for sentence_prev in mail:\n",
    "                    preprocessed_output = preprocessing(sentence_current,sentence_prev)\n",
    "                    model = w2vmodel(preprocessed_output[sentences])\n",
    "                    final_score = final_score(preprocessed_output[filtered_s1_tokens],preprocessed_output[filtered_s2_tokens],preprocessed_output[s1_tokens_pos],preprocessed_output[s2_tokens_pos],preprocessed_output[word_features],model)\n",
    "                    current_mail_sentence_sentence_prev[sentence_prev.index()] = final_score\n",
    "                sum_sim_current_mail_sentence_sentence_prev = sum(current_mail_sentence_sentence_prev)\n",
    "                current_mail_sentence_sim.append(sum_sim_current_mail_sentence_sentence_prev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
